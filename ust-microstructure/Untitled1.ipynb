{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense,Dropout,Activation, Lambda\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling1D, Flatten\n",
    "from keras.layers import MaxPooling1D, MaxPooling2D,Reshape, BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "lob = pd.read_csv(os.path.join(path, \"lob.csv\"), infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lob.columns = [\"date\", \"time\" ] + [\"bid_price{}\".format(i) for i in range(1, 6)] + \\\n",
    "    [\"ask_price{}\".format(i) for i in range(1, 6)] + [\"bid_size{}\".format(i) for i in range(1, 6)] + \\\n",
    "    [\"ask_size{}\".format(i) for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time insensitive features\n",
    "lob[\"ask_price_mean\"] = lob[\"bid_price_mean\"] = lob[\"ask_volume_mean\"] = lob[\"bid_volume_mean\"] = 0\n",
    "for i in range(1, level + 1):\n",
    "    lob[\"spread{}\".format(i)] = lob[\"ask_price{}\".format(i)] - lob[\"bid_price{}\".format(i)]\n",
    "    lob[\"mid_price{}\".format(i)] = (lob[\"ask_price{}\".format(i)] + lob[\"bid_price{}\".format(i)]) / 2\n",
    "    if i < level:\n",
    "        lob[\"ask_price_diff_{}-{}\".format(i + 1, i)] = lob[\"ask_price\" + str(i + 1)] - lob[\"ask_price\" + str(i)]\n",
    "        lob[\"bid_price_diff_{}-{}\".format(i + 1, i)] = lob[\"bid_price\" + str(i + 1)] - lob[\"bid_price\" + str(i)]\n",
    "        lob[\"ask_volume_diff_{}-{}\".format(i + 1, i)] = lob[\"ask_volume\" + str(i + 1)] - lob[\"ask_volume\" + str(i)]\n",
    "        lob[\"bid_volume_diff_{}-{}\".format(i + 1, i)] = lob[\"bid_volume\" + str(i + 1)] - lob[\"bid_volume\" + str(i)]\n",
    "    lob[\"ask_price_mean\"] += lob[\"ask_price{}\".format(i)] / level\n",
    "    lob[\"bid_price_mean\"] += lob[\"bid_price{}\".format(i)] / level\n",
    "    lob[\"ask_volume_mean\"] += lob[\"ask_volume{}\".format(i)] / level\n",
    "    lob[\"bid_volume_mean\"] += lob[\"ask_volume{}\".format(i)] / level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time sensitive features\n",
    "# to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "lob[\"mid_price\"] = lob[\"mid_price1\"]\n",
    "steps = [1, 2, 3, 5, 10]\n",
    "for step in steps:\n",
    "    lob[\"mid_price_change{}\".format(step)] = lob[\"mid_price\"].diff(period=step, axis=0)\n",
    "    lob[\"label{}\".format(step)] = 0 + 1 * (lob[\"mid_price_change{}\".format(step)] > 0) + \\\n",
    "        - 1 * (lob[\"mid_price_change{}\".format(step)] < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainday [0, 1, 2, 3, 4, 5] valdays [6, 7] colx range(0, 40) coly 148\n",
      "{'batch_size': 50, 'sequence_length': 100, 'epochs': 100, 'learning_rate': 0.001, 'learning_rate_decay': 0, 'opt': <keras.optimizers.Adam object at 0xb26b9c240>, 'save_dir': 'saved_models', 'nflag': True}\n"
     ]
    }
   ],
   "source": [
    "configs = {}\n",
    "configs['batch_size'] = 100\n",
    "configs['sequence_length'] = 100\n",
    "configs['epochs'] = 100\n",
    "configs['learning_rate'] = .001\n",
    "configs['learning_rate_decay'] = 0\n",
    "configs['opt'] = Adam(lr=configs['learning_rate'], decay=configs['learning_rate_decay'])\n",
    "configs['save_dir'] = 'saved_models'\n",
    "configs['nflag'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_11 (Conv1D)           (None, 100, 16)           1296      \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 100, 16)           528       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 100, 16)           528       \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 100, 16)           528       \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 100, 16)           528       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 106,067\n",
      "Trainable params: 106,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16, kernel_size=2, strides=1, activation='relu', padding='causal', input_shape=(100,40)))                \n",
    "model.add(Conv1D(16, kernel_size=2, dilation_rate=2, activation='relu', padding='causal'))\n",
    "model.add(Conv1D(16, kernel_size=2, dilation_rate=4, activation='relu', padding='causal'))\n",
    "model.add(Conv1D(16, kernel_size=2, dilation_rate=8, activation='relu', padding='causal'))\n",
    "model.add(Conv1D(16, kernel_size=2, dilation_rate=16, activation='relu', padding='causal'))\n",
    "model.add(Flatten())        \n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.40))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "opt = Adam(lr=configs['learning_rate'], decay=configs['learning_rate_decay'])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=configs['opt'], metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_gen,\n",
    "            validation_data=val_gen,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=validation_steps,\n",
    "            epochs=epochs,\n",
    "            verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
